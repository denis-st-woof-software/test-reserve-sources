const fs = require('fs');
const path = require('path');
const { isAddress, getAddress } = require('ethers');

// --- Helpers ---

const isEvmAddress = (value) => typeof value === 'string' && isAddress(value);

const readJson = (filePath) => {
  const raw = fs.readFileSync(filePath, 'utf8');
  try {
    return JSON.parse(raw);
  } catch (error) {
    throw new Error(`Invalid JSON: ${error.message}`);
  }
};

// --- Type validators ---

const typeValidators = {
  string: (value) => typeof value === 'string',
  number: (value) => typeof value === 'number' && Number.isFinite(value),
  boolean: (value) => typeof value === 'boolean',
  address: (value) => isEvmAddress(value),
  nullableString: (value) => value === null || typeof value === 'string',
  nullableNumber: (value) =>
    value === null || (typeof value === 'number' && Number.isFinite(value)),
  nullableAddress: (value) => value === null || isEvmAddress(value),
};

const allowedTypes = new Set(Object.keys(typeValidators));

// --- Shared context factory ---

function createContext() {
  return {
    rootDir: path.resolve(__dirname, '..'),
    configPath: path.join(__dirname, 'json-validation.config.json'),
    errors: [],
    config: undefined,
    allowedTypes,
    typeValidators,
    stats: { filesChecked: 0, itemsChecked: 0 },
    loadedFiles: [],
  };
}

// --- Pipeline steps ---

/**
 * Step A — Load and parse the config file.
 * On failure, pushes a [config] error and leaves ctx.config unset.
 */
function loadConfigStep(ctx) {
  try {
    ctx.config = readJson(ctx.configPath);
  } catch (error) {
    ctx.errors.push(`[config] ${error.message}`);
  }
}

/**
 * Step B — Validate the config structure.
 * Checks root shape, files array, each entry's path/fields, unique field names,
 * and allowed types. Skips entirely when ctx.config was not loaded.
 */
function validateConfigStep(ctx) {
  // If config failed to load, the error is already recorded — nothing to validate.
  if (ctx.config === undefined) {
    ctx.errors.push('[config] Config failed to load');
    return;
  }

  if (!ctx.config || typeof ctx.config !== 'object' || Array.isArray(ctx.config)) {
    ctx.errors.push('[config] Root must be an object');
    return;
  }

  if (!Array.isArray(ctx.config.files) || ctx.config.files.length === 0) {
    ctx.errors.push('[config] "files" must be a non-empty array');
    return;
  }

  ctx.config.files.forEach((entry, index) => {
    if (!entry || typeof entry !== 'object' || Array.isArray(entry)) {
      ctx.errors.push(`[config] File entry #${index} must be an object`);
      return;
    }

    const { path: filePath, fields } = entry;

    if (typeof filePath !== 'string' || filePath.trim().length === 0) {
      ctx.errors.push(`[config] File entry #${index} has invalid "path"`);
    }

    if (!Array.isArray(fields) || fields.length === 0) {
      ctx.errors.push(`[config] File entry #${index} has invalid "fields"`);
      return;
    }

    const fieldNames = new Set();
    fields.forEach((field, fieldIndex) => {
      if (!field || typeof field !== 'object' || Array.isArray(field)) {
        ctx.errors.push(`[config] File entry #${index} field #${fieldIndex} must be an object`);
        return;
      }

      const { name, type } = field;

      if (typeof name !== 'string' || name.trim().length === 0) {
        ctx.errors.push(`[config] File entry #${index} field #${fieldIndex} has invalid "name"`);
      } else if (fieldNames.has(name)) {
        ctx.errors.push(`[config] File entry #${index} has duplicate field name "${name}"`);
      } else {
        fieldNames.add(name);
      }

      if (typeof type !== 'string' || !ctx.allowedTypes.has(type)) {
        ctx.errors.push(`[config] File entry #${index} field #${fieldIndex} has invalid "type"`);
      }
    });
  });
}

/**
 * Step C — Validate each JSON file declared in the config.
 * Checks file existence, JSON parse, root-is-array, each item is an object,
 * required fields exist, and types match. Skips when config is absent or
 * earlier steps already recorded errors.
 */
function validateFilesStep(ctx) {
  // If config was not loaded or previous steps found errors, skip file validation
  // (mirrors original behavior: config errors prevent file-level checks).
  if (!ctx.config || ctx.errors.length > 0) return;
  if (!Array.isArray(ctx.config.files)) return;

  for (const { path: file, fields } of ctx.config.files) {
    const filePath = path.join(ctx.rootDir, file);
    ctx.stats.filesChecked++;

    if (!fs.existsSync(filePath)) {
      ctx.errors.push(`[${file}] File not found`);
      continue;
    }

    let data;
    try {
      data = readJson(filePath);
    } catch (error) {
      ctx.errors.push(`[${file}] ${error.message}`);
      continue;
    }

    if (!Array.isArray(data)) {
      ctx.errors.push(`[${file}] Root JSON must be an array`);
      continue;
    }

    ctx.loadedFiles.push({ file, data, fields });

    data.forEach((item, index) => {
      ctx.stats.itemsChecked++;

      if (!item || typeof item !== 'object' || Array.isArray(item)) {
        ctx.errors.push(`[${file}] Item #${index} is not an object`);
        return;
      }

      const missing = fields
        .map((field) => field.name)
        .filter((fieldName) => !Object.prototype.hasOwnProperty.call(item, fieldName));

      if (missing.length > 0) {
        const idHint = Object.prototype.hasOwnProperty.call(item, 'id') ? ` (id=${item.id})` : '';
        ctx.errors.push(`[${file}] Item #${index}${idHint} missing fields: ${missing.join(', ')}`);
        return;
      }

      fields.forEach((field) => {
        const value = item[field.name];
        const validator = ctx.typeValidators[field.type];

        if (!validator(value)) {
          const idHint = Object.prototype.hasOwnProperty.call(item, 'id') ? ` (id=${item.id})` : '';
          ctx.errors.push(
            `[${file}] Item #${index}${idHint} invalid "${field.name}" type (expected ${field.type})`,
          );
        }
      });
    });
  }
}

/**
 * Step D — Normalize address fields to checksummed EVM addresses.
 * Runs only when validation passed (no errors). For each loaded file and item,
 * applies getAddress to address and nullableAddress fields. Invalid values
 * are not fixed; normalization errors are recorded.
 */
function normalizeStep(ctx) {
  if (ctx.errors.length > 0) return;
  if (!ctx.loadedFiles || ctx.loadedFiles.length === 0) return;

  for (const { file, data, fields } of ctx.loadedFiles) {
    for (let index = 0; index < data.length; index++) {
      const item = data[index];
      if (!item || typeof item !== 'object' || Array.isArray(item)) continue;

      for (const field of fields) {
        const { name, type } = field;
        if (type !== 'address' && type !== 'nullableAddress') continue;

        const value = item[name];
        if (type === 'nullableAddress' && value === null) continue;

        try {
          item[name] = getAddress(value);
        } catch (error) {
          const idHint = Object.prototype.hasOwnProperty.call(item, 'id') ? ` (id=${item.id})` : '';
          ctx.errors.push(`[${file}] Item #${index}${idHint} failed to normalize "${name}"`);
        }
      }
    }
  }
}

/**
 * Step E — Finalize: report results and exit.
 * This is the single place that decides whether to print errors or success.
 */
function finalizeStep(ctx) {
  if (ctx.errors.length > 0) {
    console.error('JSON validation failed:');
    ctx.errors.forEach((message) => console.error(`- ${message}`));
    process.exit(1);
  }

  console.log('JSON validation passed.');
}

// --- Pipeline runner ---

/**
 * Execute an ordered list of synchronous steps, passing the shared context
 * to each one. Steps read/write ctx freely; the runner simply iterates.
 */
function runPipeline(steps, ctx) {
  for (const step of steps) {
    step(ctx);
  }
}

// --- Main ---

const steps = [loadConfigStep, validateConfigStep, validateFilesStep, normalizeStep, finalizeStep];
const ctx = createContext();
runPipeline(steps, ctx);
